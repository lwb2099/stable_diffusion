{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Train_UNet",
            "type": "python",
            "request": "launch",
            "module": "accelerate.commands.launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--config_file", "stable_diffusion/config/accelerate_config/deepspeed.yaml",
                "--main_process_port", "29511",
                "train_unet.py",
                // //* logging
                // "--with-tracking",
                // "--report-to", "wandb",
                // //* data
                // "--dataset", "poloclub/diffusiondb",
                "--subset", "2m_first_10k",
                // "--data-dir", "data/dataset",
                // "--resolution", "64", 
                // "--random-flip",
                // "--max-train-samples", "9000",
                // "--max-val-samples", "500",
                // "--max-test-samples", "500",
                // // "--dataloader-num-workers", "4",
                // //* checkpointing
                // "--model-dir", "data/pretrained",
                // "--output-dir", "model",
                // "--checkpointing-steps", "100", // save every 100 steps
                // //* model
                // // unet:
                // "--num-res-blocks", "2",
                // "--n-heads", "8",
                // "--attention-resolutions", "0,1",
                "--channels-list", "32",  // "160,320,640,640",
                // "--time-emb-dim", "512",
                // "--dropout", "0.1",
                // "--n-layers", "2",
                // "--context-dim", "768", // match CLIP madel
                // // scheduler
                // "--noise-schedule", "linear",
                // "--noise-steps", "1000",
                // "--beta-start", "0.0001",
                // "--beta-end", "0.02",
                // // clip
                // "--tokenizer", "runwayml/stable-diffusion-v1-5",
                // "--text-encoder", "runwayml/stable-diffusion-v1-5",
                // "--max-seq-len", "77",
                // "--model-dir", "data/pretrained",
                // //* training
                // "--seed", "42",
                "--train-batch-size", "1",
                // "--eval-batch-size", "8",
                "--max-train-steps", "20",
                // "--guidance-scale", "7.5",
                // // "--max-train-epochs", "10",
                // "--log-interval", "100",
                // "--learning-rate", "0.0001",
                // "--adam-weight-decay", "0.1",
                // "--lr-warmup-steps", "500",
                // // ditributed
                // "--use-deepspeed",
                // // "--use-8bit-adam",             
            ]
        },
        {
            "name": "Train_AutoEncoder",
            "type": "python",
            "request": "launch",
            "module": "accelerate.commands.launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--config_file", "stable_diffusion/config/accelerate_config/deepspeed.yaml",
                "--main_process_port", "29511",
                "train_autoencoder.py",
                // //* logging
                // "--with-tracking",
                // "--report-to", "wandb",
                // //* data
                // "--dataset", "poloclub/diffusiondb",
                "--subset", "2m_first_10k",
                // "--data-dir", "data/dataset",
                // "--resolution", "64", 
                // "--random-flip",
                // "--max-train-samples", "9000",
                // "--max-val-samples", "500",
                // "--max-test-samples", "500",
                // // "--dataloader-num-workers", "4",
                // //* checkpointing
                // "--model-dir", "data/pretrained",
                // "--output-dir", "model",
                // "--checkpointing-steps", "100", // save every 100 steps
                // //* model
                // // autoencoder
                // "--in-channels","3",
                // "--latent-channels", "4",
                // "--out-channels", "3",
                // "--autoencoder-channels-list", "64,128",
                // "--groups", "32",
                // "--autoencoder-num-res-blocks", "2",
                // //* training
                // "--seed", "42",
                "--train-batch-size", "1",
                // "--eval-batch-size", "8",
                "--max-train-steps", "20",
                // "--guidance-scale", "7.5",
                // // "--max-train-epochs", "10",
                // "--log-interval", "100",
                // "--learning-rate", "0.0001",
                // "--adam-weight-decay", "0.1",
                // "--lr-warmup-steps", "500",
                // // ditributed
                // "--use-deepspeed",
                // // "--use-8bit-adam",             
            ]
        },
        {
            "name": "Sample_txt2img",
            "type": "python",
            "request": "launch",
            "program": "scripts/txt2img.py",
            "console": "integratedTerminal",
            "justMyCode": false,
        }
    ]
}